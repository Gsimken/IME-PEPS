
library(ggpubr)
library(knitr)
library(tidyr)

# Usaremos las funciones para hacer esta función
require(ez)

# Definimos los datos
duraciones <- c("0 día", "2 días", "4 días", "6 días")
t1 <- c(26, 27, 28, 28, 33)
t2 <- c(22, 23, 24, 27, 27)
t3 <- c(19, 20, 21, 23, 27)
t4 <- c(19, 20, 23, 24, 24)
dx4 <- list(t1, t2, t3, t4)
datos.wide <- data.frame(dx4)
colnames(datos.wide) <- duraciones

# Pero los procedimientos para hacer ANOVA, y muchas rutinas para
# graficar, requieren los datos en formalo largo (long).
dl <- gather(
  data = datos.wide,
  key = "Duración",
  value = "Errores",
  duraciones
)
Desarrollador <- factor(rep(1:nrow(datos.wide), ncol(datos.wide)))
datos.long <- cbind(Desarrollador, dl)
datos.long[["Duración"]] <- factor(datos.long[["Duración"]])

# Una primera aproximación es comparar los tratamientos con una gráfico
# de cajas.
p1 <- ggboxplot(
  datos.long,
  x = "Duración", y = "Errores",
  xlab = "Duración capacitación", ylab = "Errores",
  color = "Duración",
  add = "jitter",
  add.params = list(color = "Duración", fill = "Duración")
)
print(p1)


# Como son los mismos datos que analizamos como grupos independientes,
# se observa una disminución en el número de errores a medida que se
# aumentan los días de capacitación.


# ----------------------------------------------------
# Hipótesis
# ----------------------------------------------------

# ¿Cuáles serían las hipótesis en este caso?
#
# Luego, en este caso:
# H0: La media del nº de pruebas unitarias falladas por sprint es la
#     misma en todas las mediciones aplicadas a los desarrolladores
# HA: La media de pruebas falladas en al menos una medición aplicada a
#     los desarrolladores es distinta
#


# ----------------------------------------------------
# Verificaciones
# ----------------------------------------------------

# Estas se explican en el capítulo 15 de VarssarStats:
# 1. La variable dependiente tiene escala de intervalo
# 2. Las muestras son independientes al *interior* de los grupos
# 3. Se puede asumir que las poblaciones son aproximadamente normales
# 4. Las muestras tienen varianzas similares
# 5. La matriz de varianzas-covarianzas es esférica

# La condición 1 se verifica, ya que en 5 y 15 errores hay 10 errores
# de diferencia, lo mismo que entre 10 y 20.

# La condición 2 también se verifica en el enunciado.

# Para la condición 3, obtenemos el mismo gráfico QQ que vimos para el
# caso de muestras independientes (porque usamos los mimos valores).
p2 <- ggqqplot(
  datos.long,
  x = "Errores",
  color = "Duración"
)
p2 <- p2 + facet_wrap(~Duración)

# Luego, aunque hay un par de puntos más o menos problemáticos, no hay
# desviaciones importantes en los datos, lo que fue confirmado con
# pruebas de normalidad de Shapiro-Wilk.

# También revisamos que se cumple la homocedasticidad con estos datos,
# condición 4, usando la prueba de Levene.

# Falta entonces la condición de esfericidad. La verdad es que esto no
# es fácil y es un conjunto de supociciones que se deben manejar.
# Una alternativa simple es decir que todos los pares de diferencias
# entre mediciones (en este caso 0/2, 0/4, 0/6, 2/4, 2/6 y 4/6 días)
# tienen igual varianza.
# Por fortuna, existe una prueba de esferidad propuesta por John W.
# Mauchly, aunque no tiene mucho poder estadístico con muestras
# reducidas.
# [JW Mauchly (1940). "Significance test for sphericity of a normal
# n-variate distribution." The Annals of Mathematical Statistics, 11,
# 204-209].

# Esta prueba está implementada en R, pero requiere de un modelo ya
# construido para hacer las estimaciones. Posterguemos esta prueba
# hasta que usemos la función ezANOVA().

# En todo caso, siempre se hace los cálculos de ANOVA-RM suponiendo que
# se cumple la condición de esfericidad. Si se llega a determinar que
# esta en realidad no se cumple, se puede aplicar una corrección de los
# grados de libertad y, por lo tanto, de los p-valores que se estimen.
# Los paquetes estadísticos, en general, suelen reportar estas
# correcciones para ser consideradas. Esta propuesta es la que también
# adopta la función ezANOVA().





# ----------------------------------------------------
# Usando las funciones del paquete ez
# ----------------------------------------------------

# La función ezANOVA() no acepta (directamente) nombres de las columnas
# en variables de texto. Por eso, usamos los nombres que hemos fijado de
# "forma dura".
ez.aov <- ezANOVA(
  data = datos.long,
  dv = Errores,
  wid = Desarrollador,
  within = Duración,
  type = 3,
  return_aov = TRUE
)
print(ez.aov)


# Podemos el el resultado gráficamente.
ezp <- ezPlot(
  data = datos.long,
  dv = Errores,
  wid = Desarrollador,
  within = Duración,
  type = 3,
  x = Duración
)
print(ezp)


# Podemos ver que, asumiendo esfericidad, se tiene un p-valor < .001.

# La función también reporta un p-valor = 0.478 para la prueba de
# esfericidad, por lo que estos datos sí estarían cumpliendo esa
# condición.

# Si esto no fuera así, y la prueba de esfericidad resultara
# estadísticamente significativa, habría que considerar las correcciones
# de Greenhouse-Geisser o las de Huynh-Feldt, ambas reportadas por la
# función, y considerar en consecuencia p-valores mayores a los
# estimados asumiendo esfericidad (.0004764 y .0000295 respectivamente,
# en vez del .0000021 original).

# Entonces, corresponde hacer hacer un análisis post hoc.


# ----------------------------------------------------
# Análisis post-hoc
# ----------------------------------------------------

# Aquí, todavía podemos hacer pruebas T de Student entre pares de
# tratamientos, pero teniendo cuidado de usar pruebas para datos
# apareados.
mc <- pairwise.t.test(datos.long[["Errores"]], datos.long[["Duración"]],
                      paired = TRUE, p.adjust.method = "holm")
cat("\n\n")
cat("Comparaciones múltiples entre los tratamientos:\n")
cat("-----------------------------------------------\n")
print(mc)


# Pero ahora no tenemos disponibles el método de Tukey
# No funciona: mt <- TukeyHSD(ez.aov[["aov"]])
# Una opción es implementar lo que se describe en VarssarStats:

# ---------------------------------------------------------------
# Procedimiento manual para obtener contrastes y ajustes de Tukey
# [capítulo 14, ajustando según capítulo 15]
# ---------------------------------------------------------------

# Obtenemos las diferencias entre todos los pares de tratamientos
diferencias <- outer(media.por.tratamiento, media.por.tratamiento, "-")
triang <- upper.tri(diferencias)
difs <- diferencias[triang]

# Ahora obtenemos los estadísticos Q (Tukey)
den <- sqrt(MS.error / N.sujetos)
Qs <- difs / den

# Para obtener los intervalos con un nivel de confianza dado
α <- 0.05
qα <- qtukey(1 - α, k, df.error)
meα <- qα * den
ics.l <- difs - meα
ics.u <- difs + meα

# Finalmente necesitamos los p-valores ajustados
pvals <- ptukey(abs(Qs), k, df.error, lower.tail = FALSE)

# Para contruir la tabla, necesitamos los pares de diferencias
nombres <- names(media.por.tratamiento)
pares <- outer(nombres, nombres, "paste", sep = " - ")
contrastes <- pares[triang]

# Creamos la tabla
m <- length(contrastes)
dnames <- list(contrastes, c("diff", "lwr", "upr","p adj"))
valores <- round(c(difs, ics.l, ics.u, pvals), 4)
tabla.tukey <- array(valores, c(m, 4), dnames)

# Y la mostramos en pantalla como la función TukeyHSD()
cat("\n\n")
cat("Comparaciones múltiples entre tratamientos según VarssarStats\n")
cat("-------------------------------------------------------------\n")
cat("  Tukey multiple comparisons of means\n")
cat("    ", (1-α)*100, "% family-wise confidence level", "\n", sep = "")
cat("\n")
cat("$Duración\n")
print(tabla.tukey, row.names = FALSE, justify = "left")
cat("\n\n")


# Con esto, podemos concluir que dar 2 días de capacitación a los
# desarrolladores disminuye *significativamente* el número de errores
# promedio que comenten sin capacitación. También vemos que entregar
# otros 2 días de capacitación (4 en total) permite disminuir todavía
# más el número de errores promedio que cometen los desarrolladores.
# Pero otros dos días de capacitación no tiene un efecto
# estadísticamente significativo en el número promedio de errores que
# estos cometen.



# ---------------------------------------------------------------
# Tukey implementado en R (extra, no evaluado en este curso)
# ---------------------------------------------------------------

# Aunque está fuera del ámbito de este curso, hoy en día van ganando
# terreno el uso de modelos mixtos.
# Esto es fácil si el factor que produce el efecto lo consideramos fijo,
# y consideramos que los sujetos fueron elegidos al azar... un factor
# fijo y otro aleatorio.
# Ya hay varias implementaciones de análisis con modelos mixtos en R.
# Un artículo que los revisa bien se encuentra en:
#     https://rpsychologist.com/r-guide-longitudinal-lme-lmer

# Usemos el paquete 'nlme' en este caso
library(nlme)

# Ahora, obtengamos un modelo mixto con 'Duración' como factor fijo y
# 'Desarrollador' como factor aleatorio.
mix <- lme(Errores ~ Duración, data = datos.long, random = ~1|Desarrollador)

# Pero los modelos mixtos son muy flexibles y se les puede consultar
# mucha información. Una tabla ANOVA es solo una de esas. Luego, hay que
# hacerlo explícitamente.

cat("\n\n")
cat("Tabla ANOVA construida con un modelo mixto\n")
cat("-----------------------------------------\n")
print(anova(mix))
cat("\n\n")

# Los modelos mixtos también permite hacer muchos tipos de "contrastes",
# esto es, comparaciones entre grupos.
# Hay paquetes de R dedicados a esto, en particular el paquete 'emmeans'
# (estimated marginal means, EMM) que tiene relación con cómo se
# calculan las medias cuando estamos "juntando" medias de varios grupos.
# o tratamientos. Pero también esto está fuera del alcance de este curso.
# En fin, por defecto, el método pairs() de este paquete asume el ajuste
# de las comparaciones de pares de tratamientos con el método de Tukey.
# Por supuesto, se puede cambiar si se quiere otro tipo de ajuste.

library(emmeans)
em <- emmeans(mix, "Duración")
tem <- pairs(em)
# print(em)
cat("\n\n")
cat("Comparaciones de las diferencias de los tratamientos con EMM\n")
cat("------------------------------------------------------------\n")
print(tem)
cat("Intervalos de confianza con EMM\n")
cat("-------------------------------\n")
print(confint(tem))
cat("\n\n")


# De forma similar, se puede obtener los mismos resultados con el
# paquete 'lsmeans' (Least square means), que otra forma en que los
# estadísticos llaman a las medias marginales.
#
# library(lsmeans)
# lsm <- lsmeans(mix, "Duración")
# tlsm <- pairs(lsm, adjust = "tukey")
# print(tlsm)


# Note que, a pesar que aparece frecuentemente el siguiente código como
# opción en los foros (con el paquete 'multcomp'), esta no sirve porque
# se usa el contraste de Tukey, es decir todos los pares de diferencias,
# pero no se ajustan los p-valores con el estadístico Q de Tukey.
#
# library(multcomp)
# ht <- glht(mix, linfct = mcp(Duración = "Tukey"))
# print(summary(ht))
